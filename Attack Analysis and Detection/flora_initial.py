# -*- coding: utf-8 -*-
"""FloRa initial

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AAjM9HGnzTT7t18TFujcE7Yfa9a_AFGm
"""

import pandas as pd
import matplotlib.pyplot as plt

df=pd.read_csv('/content/drive/MyDrive/SDN/Normal flow/Normal_packets.csv')

df.describe()

# Calculate mean duration for rows with the same source IP, destination IP, and protocol
mean_duration = df.groupby(['Source_ip', 'Destination_ip', 'Protocol'])['Duration'].mean()

# Display the mean duration
print(mean_duration)

#df_new['N_Packets'] = pd.to_numeric(df_new['N_Packets'])
mean_packets = df.groupby(['Source_ip', 'Destination_ip', 'Protocol'])['N_Packets'].mean()

# Display the mean duration
print(mean_packets)

#df_new['N_Bytes'] = pd.to_numeric(df_new['N_Bytes'])
mean_bytes = df.groupby(['Source_ip', 'Destination_ip', 'Protocol'])['N_Bytes'].mean()

# Display the mean duration
print(mean_bytes)

#df['Duration'] = pd.to_numeric(df['Duration'].str.replace('s', ''))

# Calculate mean of duration, n_bytes, and n_packets for rows with the same source IP, destination IP, and protocol
mean_values = df.groupby(['Source_ip', 'Destination_ip', 'Protocol']).agg({'Duration': 'mean', 'N_Bytes': 'mean', 'N_Packets': 'mean'})

# Calculate the ratio of packets and bytes with respect to duration
mean_values['Packet_Ratio'] = mean_duration
mean_values['Byte_Ratio'] = mean_packets

# Plot the comparative graph
mean_values[['Packet_Ratio', 'Byte_Ratio']].plot(kind='area', figsize=(10, 6))
plt.xlabel('Source IP, Destination IP, Protocol')
plt.ylabel('Ratio')
plt.title('Ratio of Packets and Bytes with respect to Duration')
plt.legend(['Packet Ratio', 'Byte Ratio'])
plt.xticks(rotation=0)
plt.show()

#df['Duration'] = pd.to_numeric(df['Duration'].str.replace('s', ''))

# Calculate mean of duration, n_bytes, and n_packets for rows with the same source IP, destination IP, and protocol
mean_values = df.groupby(['Source_ip', 'Destination_ip', 'Protocol']).agg({'Duration': 'mean', 'N_Bytes': 'mean', 'N_Packets': 'mean'})

# Calculate the ratio of packets and bytes with respect to duration
mean_values['Packet_Ratio'] = mean_duration
mean_values['Byte_Ratio'] = mean_bytes

# Plot the comparative graph
mean_values[['Packet_Ratio', 'Byte_Ratio']].plot(kind='area', figsize=(10, 6))
plt.xlabel('Source IP, Destination IP, Protocol')
plt.ylabel('Ratio')
plt.title('Ratio of Packets and Bytes with respect to Duration')
plt.legend(['Packet Ratio', 'Byte Ratio'])
plt.xticks(rotation=0)
plt.show()

plt.hist(mean_duration, bins=10, edgecolor='yellow')

# Add labels and title
plt.xlabel('Duration')
plt.ylabel('Rules')
plt.title('Histogram')

# Display the plot
plt.show()

plt.scatter(mean_duration, mean_packets)
plt.xlabel('Mean Duration')
plt.ylabel('Mean Number of Packets')
plt.title('Mean Duration vs. Mean Number of Packets')
#plt.yticks(range(0, 100))
plt.show()

plt.scatter(mean_duration, mean_bytes)
plt.xlabel('Mean Duration')
plt.ylabel('Mean Number of Bytes')
plt.title('Mean Duration vs. Mean Number of Packets')
#plt.yticks(range(0, 100))
plt.show()

Attack=pd.read_csv('/content/drive/MyDrive/SDN/Attack.csv')

d=Attack['Duration']
p=Attack['N_Packets']
b=Attack['N_Bytes']
d1=df['Duration']
p1=df['N_Packets']
b1=df['N_Bytes']

attack_mean_duration = Attack["Duration"].mean()
attack_mean_packets = Attack["N_Packets"].mean()

normal_mean_duration = df["Duration"].mean()
normal_mean_packets = df["N_Packets"].mean()

plt.plot([0, attack_mean_duration], [0, attack_mean_packets], color="red", label="Attack")
plt.plot([0, normal_mean_duration], [0, normal_mean_packets], color="blue", label="Normal")

plt.xlabel("Mean Duration")
plt.ylabel("Mean Packets")
plt.title("Comparison of Attack and Normal Datasets")
plt.legend()

plt.xlim(0, 200)  # Limit the x-axis range till 100

plt.show()

plt.scatter(d, p, color="red", label="Attack")
plt.scatter(d1,p1, color="blue", label="Normal")

plt.xlabel("Mean Duration")
plt.ylabel("Mean Packets")
plt.title("Comparison of Attack and Normal Datasets")
#plt.legend()

plt.show()

plt.scatter(d, b, color="red", label="Attack")
plt.scatter(d1,b1, color="blue", label="Normal")

plt.xlabel("Mean Duration")
plt.ylabel("Mean Bytes")
plt.title("Comparison of Attack and Normal Datasets")
plt.legend()

plt.show()

Attack1=pd.read_csv('/content/drive/MyDrive/SDN/Attack Flow/Attack_Flows.csv')

Attack1

column_names = ['0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','19']  # List of column names
Attack1.columns = column_names

columns_to_drop=['0','2','6','7','9','10','11','12','15','16','17','19']
Attack1=Attack1.drop(columns=columns_to_drop)
#df=df.drop(columns='0')

new_columns = {'1': 'Duration', '3': 'N_Packets','4':'N_Bytes','5':'Idle_timeout','8':'Protocol','13':'Source_ip','14':'Destination_ip'}
Attack1= Attack1.rename(columns=new_columns)

Attack1['Duration'] = Attack1['Duration'].str.replace('duration=', '')
Attack1['N_Packets'] = Attack1['N_Packets'].str.replace('n_packets=', '')
Attack1['N_Bytes'] = Attack1['N_Bytes'].str.replace('n_bytes=', '')
Attack1['Idle_timeout'] = Attack1['Idle_timeout'].str.replace('idle_timeout=', '')
Attack1['Source_ip'] = Attack1['Source_ip'].str.replace('nw_src=', '')
Attack1['Destination_ip'] = Attack1['Destination_ip'].str.replace('nw_dst=', '')

Attack1['Duration'] = pd.to_numeric(Attack1['Duration'].str.replace('s', ''))

mean_duration = Attack1.groupby(['Source_ip', 'Destination_ip', 'Protocol'])['Duration'].mean()

# Display the mean duration
print(mean_duration)

Attack1['N_Packets'] = pd.to_numeric(Attack1['N_Packets'])
mean_packets1 = Attack1.groupby(['Source_ip', 'Destination_ip', 'Protocol'])['N_Packets'].mean()

# Display the mean duration
print(mean_packets1)

attack_mean_duration1 = Attack1["Duration"].mean()
attack_mean_packets1 = Attack1["N_Packets"].mean()

normal_mean_duration = df["Duration"].mean()
normal_mean_packets = df["N_Packets"].mean()

plt.plot([0, attack_mean_duration1], [0, attack_mean_packets1], color="red", label="Attack")
plt.plot([0, normal_mean_duration], [0, normal_mean_packets], color="blue", label="Normal")

plt.xlabel("Mean Duration")
plt.ylabel("Mean Packets")
plt.title("Comparison of Attack and Normal Datasets")
plt.legend()

plt.xlim(0, 225)  # Limit the x-axis range till 100

plt.show()

Attack1['N_Bytes'] = pd.to_numeric(Attack1['N_Bytes'])
attack_mean_duration1 = Attack1["Duration"].mean()
attack_mean_packets1 = Attack1["N_Bytes"].mean()

normal_mean_duration = df["Duration"].mean()
normal_mean_packets = df["N_Bytes"].mean()

plt.plot([0, attack_mean_duration1], [0, attack_mean_packets1], color="red", label="Attack")
plt.plot([0, normal_mean_duration], [0, normal_mean_packets], color="blue", label="Normal")

plt.xlabel("Mean Duration")
plt.ylabel("Mean Bytes")
plt.title("Comparison of Attack and Normal Datasets")
plt.legend()

plt.xlim(0, 225)  # Limit the x-axis range till 100

plt.show()

df['label']=1
Attack1['label']=0

frames=[df,Attack1]
Final_df=pd.concat(frames)

Final_df

shuffled_df = Final_df.sample(frac=1).reset_index(drop=True)

shuffled_df=shuffled_df.rename(columns={'Coefficient_of_Variation':'CVB'})

shuffled_df

shuffled_df.to_csv('/content/drive/MyDrive/SDN/Final_Dataset.csv')



y=shuffled_df['label']

bdf=pd.read_csv("/content/drive/MyDrive/SDN/balanced_dataset.csv")

X=bdf[['Duration_x','N_Packets_x','N_Packets_y','N_Bytes_x','Duration_y','N_Bytes_y']]

Y=bdf['label']

import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

from sklearn.preprocessing import MinMaxScaler

# Create a MinMaxScaler object
scaler = MinMaxScaler()

# Fit and transform the data
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)

X_train1, X_test1, y_train1, y_test1 = train_test_split(X_standardized, y, test_size=0.8)

model = xgb.XGBClassifier(n_estimators=1 )
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

pip install catboost

from catboost import CatBoostClassifier
catboost_classifier = CatBoostClassifier(silent=True)  # Suppress CatBoost's output

# Train the classifier
catboost_classifier.fit(X_train, y_train)

# Make predictions on the test set
y_pred = catboost_classifier.predict(X_test)

# Calculate the accuracy of the model
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

print(f"Accuracy: {accuracy}")
print(f"Classification Report:\n{report}")

# import numpy as np
# from sklearn .metrics import roc_auc_score

# auc = np.round(roc_auc_score(y_test, y_pred))
# print("Auc for our sample data is {}".format(auc))

from sklearn.metrics import confusion_matrix

# Assuming you have already trained the XGBoost model and made predictions (y_pred)
# y_test contains the true labels of the test set

# Calculate the confusion matrix
cm = confusion_matrix(y_test, y_pred)

print("Confusion Matrix:")
print(cm)

from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Initialize the SVM classifier
svm_classifier = SVC()

svm_classifier.fit(X_train, y_train)

y_pred = svm_classifier.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

# Step 1: Prepare your data (X: features, y: target)
# Replace 'X_train', 'X_test', 'y_train', 'y_test' with your data
#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 2: Initialize the logistic regression model
logreg = LogisticRegression()

# Step 3: Train the model
logreg.fit(X_train, y_train)

# Step 4: Make predictions and evaluate the model
y_pred = logreg.predict(X_test)

# Calculate evaluation metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
# Print the evaluation metrics and confusion matrix
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

#mean_duration_df = shuffled_df.groupby(['Source_ip', 'Destination_ip'])['Duration_x'].mean().reset_index()
mean_duration_df = shuffled_df.groupby(['Source_ip', 'Destination_ip'])['N_Bytes'].mean().reset_index()

shuffled_df = shuffled_df.merge(grouped_stats, on=['Source_ip', 'Destination_ip'], how='left')

import pandas as pd

# Assuming you have a DataFrame called shuffled_df with 'N_Packets' column
# Calculate the standard deviation and mean of N_Packets for each group
grouped_stats = shuffled_df.groupby(['Source_ip', 'Destination_ip'])['N_Bytes_x'].agg(['std', 'mean'])

# Calculate the coefficient of variance (CV) for each group
grouped_stats['CVB'] = grouped_stats['std'] / grouped_stats['mean']

# Reset the index to make it a DataFrame
grouped_stats.reset_index(inplace=True)

print(grouped_stats)

import pandas as pd

# Assuming you have a DataFrame called df
# Replace NaN values with the mode of each column
for column in grouped_stats.columns:
    mode_value = grouped_stats['std'].mode()[0]  # Calculate the mode for each column
    grouped_stats['std'].fillna(mode_value, inplace=True)  # Replace NaN values with the mode

# Now the NaN values have been replaced with the mode in each column

import pandas as pd

# Assuming you have a DataFrame called df
# Replace NaN values with the mode of each column
for column in grouped_stats.columns:
    mode_value = grouped_stats['CVB'].mode()[0]  # Calculate the mode for each column
    grouped_stats['CVB'].fillna(mode_value, inplace=True)  # Replace NaN values with the mode

# Now the NaN values have been replaced with the mode in each column

grouped_stats.isna().sum()

import pandas as pd

# Assuming you have a DataFrame called df and a column called 'N_Packets'
# Calculate the standard deviation of 'N_Packets'
std_deviation = shuffled_df['N_Packets_x'].std()

print(std_deviation)

# #pip install imbalanced-learn
# from imblearn.over_sampling import SMOTE
# smote = SMOTE(sampling_strategy='auto')

#X_resampled, y_resampled = smote.fit_resample(X, y)

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Assuming 'df' is your DataFrame with data
correlation_matrix = shuffled_df.corr()
sns.heatmap(correlation_matrix, annot=True)
plt.title('Heatmap')
plt.show()

from sklearn.preprocessing import StandardScaler

# Create a StandardScaler object
scaler = StandardScaler()

# Fit and transform the data
X_standardized = scaler.fit_transform(X1)

import numpy as np
import pandas as pd
from sklearn.model_selection import StratifiedKFold
from sklearn.ensemble import RandomForestClassifier

rf_classifier = RandomForestClassifier(n_estimators=50)
kfold = StratifiedKFold(n_splits=5)

import numpy as np
import pandas as pd
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC  # Replace with your desired classifier

# Assuming your dataset is stored in a DataFrame called 'df'
#X = df.drop('label', axis=1)
#y = df['label']

svm_classifier = SVC()  # Replace with your desired classifier and hyperparameters

# Perform 5-fold cross-validation
cv_scores = cross_val_score(svm_classifier, X1, y, cv=5)

print("Cross-validation scores:", cv_scores)
print("Mean CV score:", np.mean(cv_scores))

svm_classifier.fit(X_train1,y_train1)

pred2=svm_classifier.predict(X_test1)

accuracy = accuracy_score(y_test1, pred2)
print(accuracy)

import lightgbm as lgb

train_data = lgb.Dataset(X_train, label=y_train)
test_data = lgb.Dataset(X_test, label=y_test)

params = {
    'objective': 'binary',  # For binary classification
    'metric': 'binary_logloss',  # Logarithmic loss metric
    'boosting_type': 'gbdt',  # Gradient Boosting Decision Tree
    'num_leaves': 31,
    'learning_rate': 0.05,
    'feature_fraction': 0.9,
    'bagging_fraction': 0.8,
    'bagging_freq': 5,
    'verbose': 0,
    'num_threads': 4  # Number of CPU threads to use during training
}

y_pred = model.predict(X_test)

from sklearn.metrics import accuracy_score, roc_auc_score

# For binary classification
y_pred_binary = [1 if pred >= 0.5 else 0 for pred in y_pred]
accuracy = accuracy_score(y_test, y_pred_binary)
roc_auc = roc_auc_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
print(f"ROC AUC Score: {roc_auc}")

